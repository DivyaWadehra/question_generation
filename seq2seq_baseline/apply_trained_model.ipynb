{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1           1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2           2  Managed by her father, Mathew Knowles, the gro...   \n",
       "3           3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4           4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question  \n",
       "0           When did Beyonce start becoming popular?  \n",
       "1  What areas did Beyonce compete in when she was...  \n",
       "2  When did Beyonce leave Destiny's Child and bec...  \n",
       "3      In what city and state did Beyonce  grow up?   \n",
       "4         In which decade did Beyonce become famous?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ИЗМЕНИТЬ ПУТЬ В ЗАВИСИМОСТИ ОТ ТОГО ГДЕ ЗАПУСКАЕМ КОД\n",
    "try:\n",
    "    df = pd.read_csv(\"ctx_quest.csv\")\n",
    "except:\n",
    "    df = pd.read_csv(\"/Users/lilyakhoang/input/question_generation/ctx_quest.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потом можете добавить свою предобработку\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When did the U.N. vote to adopt the Sustainable Development Goals?',\n",
       " \"In what case can a referee's decision be overturned?\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_data = []\n",
    "all_text_data.extend(list(df['context']))\n",
    "all_text_data.extend(list(df['question']))\n",
    "all_text_data = list(set(all_text_data))\n",
    "cleaned_text_data = [x for x in all_text_data if 'float' not in str(type(x))]\n",
    "cleaned_text_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bc93c4e9f643f6b7aa7d3854a23770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144855), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(cleaned_text_data):\n",
    "  \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c214b321df2241c8bcd1ee9b92444345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Read word2vec', max=400000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ИЗМЕНИТЬ ПУТЬ В ЗАВИСИМОСТИ ОТ ТОГО ГДЕ ЗАПУСКАЕМ КОД\n",
    "local_path = \"/Users/lilyakhoang/input/glove.6B/glove.6B.50d.txt\"\n",
    "this_folder_path = \"glove.6B.50d.txt\"\n",
    "\n",
    "word2index = {'PAD': 0}\n",
    "vectors = []\n",
    "   \n",
    "try:\n",
    "    lines = open(local_path)\n",
    "except:\n",
    "    lines = open(this_folder_path)\n",
    "    \n",
    "embedding_dim = 50\n",
    "# Zero vector for PAD\n",
    "vectors.append(np.zeros((1, embedding_dim)))\n",
    "progress_bar = tqdm(desc='Read word2vec', total=400000)\n",
    "\n",
    "for line in lines:\n",
    "    current_word = line.split()[0]\n",
    "    if current_word in word2freq:\n",
    "\n",
    "        word2index[current_word] = len(word2index)\n",
    "\n",
    "        # current_vectors = current_parts[-embedding_dim:]\n",
    "        current_vectors = line.split()[1:]\n",
    "        current_vectors = np.array(list(map(float, current_vectors)))\n",
    "        current_vectors = np.expand_dims(current_vectors, 0)\n",
    "\n",
    "        vectors.append(current_vectors)\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "vectors = np.concatenate(vectors)\n",
    "\n",
    "lines.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vectors=vectors):#input_size\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden, debug = False):\n",
    "        if debug == True: \n",
    "            print(\"====ENCODING_FORWARD====\")\n",
    "            print(\"input.shape\", input.shape)\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        if debug == True: \n",
    "            print(\"embedded/output.shape\",embedded.shape,\"hidden.shape\", hidden.shape  )\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, vectors):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        # self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, self.vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, debug = False):\n",
    "        if debug == True:\n",
    "          print(\"===FORWARD_DECODER===\")\n",
    "          print(\"input.shape {}, hidden.shape {}\".format(input.shape,hidden.shape ))\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    def __init__(self, context , word2index, context_sequence_length=80, \n",
    "                 pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.context_sequence_length = context_sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(context, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        # Место для вашей предобработки\n",
    "    \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for ctx_sent in data_iterator:\n",
    "            ctx = self.process_text(ctx_sent)\n",
    "            indexed_ctx = self.indexing(ctx)\n",
    "            self.x_data.append(indexed_ctx)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        indexes = []\n",
    "        for word in tokenized_text:\n",
    "          if word in self.word2index:\n",
    "            indexes.append(self.word2index[word])\n",
    "        return indexes\n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        count = 0 \n",
    "        paded_seq = []\n",
    "        for seq_el in sequence:\n",
    "              paded_seq.append(seq_el)\n",
    "              count += 1\n",
    "              if count >= self.context_sequence_length: break\n",
    "        if count < self.context_sequence_length:\n",
    "          for ind in range(count, self.context_sequence_length):\n",
    "            paded_seq.append(self.pad_index)\n",
    "        return paded_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da06285a2abe4b6b982901c726130f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading data', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = WordData(context, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33972, 33404, 16932,    11,  3127,   270,  8242,    11, 36992,    11,\n",
       "          200,    24,    23,   375,   437,   405,     2,  2852,    24,    14,\n",
       "           28,   137,  2195,     2,  9315,     2,   380,  1913,     6,  2844,\n",
       "            3,   375,     6,  1059,     7,  1971,     2,   736,     2,    66,\n",
       "         1767,     7,   904,  4027,     6,  5264,  5557,    19,     8,   951,\n",
       "            2,     6,   480,     5,  3101,     7,     1,   284,  2222,    19,\n",
       "          406,  2195,     4,  1886,  1146,  1535,  1728,    11,   126,  9697,\n",
       "           56,  1513,   951,     3,  1743,    21,    69,   623,     2, 23818])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, drop_last = True)\n",
    "for x,in data_loader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_no_att = torch.load(\"/Users/lilyakhoang/Desktop/dl_project_out_of_git/Encoder_no_attention_5_epochs_2.7\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_no_att = torch.load(\"/Users/lilyakhoang/Desktop/dl_project_out_of_git/Decoder_no_attention_5_epochs_2.7\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {word2index[k]:k for k in word2index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tourism'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word[2423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_trial = [\"\"\"Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, \n",
    "Texas, she performed in various singing and dancing competitions as a child,\n",
    "and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's\n",
    "Child. Managed by her father, Mathew Knowles, the group became one of the world's \n",
    "best-selling girl groups of all time.\"\"\"]\n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_trial = [\"\"\"Texas, she performed in various singing and dancing competitions as a child,\n",
    "and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child.\"\"\"]\n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d5dabb9be9422c955fd9bb196a8150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading data', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT ==>  beyoncé giselle knowles - carter / bee - yon - say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl - group destiny ' s child . managed by her father , mathew\n",
      "\n",
      "QUESTION ==>   what PAD\n"
     ]
    }
   ],
   "source": [
    "def predict(context_list, encoder, decoder):\n",
    "    dataset = WordData(context_list, word2index)\n",
    "    data_loader = DataLoader(dataset, drop_last = True)\n",
    "    for context_tensor in data_loader:\n",
    "        context_tensor_words = [index2word[int(index)] for index in context_tensor[0] if index != 0]\n",
    "        context_tensor_words = ' '.join(context_tensor_words)\n",
    "        print(\"CONTEXT ==> \",context_tensor_words)\n",
    "        output_question = ''\n",
    "        with torch.no_grad():\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_output, encoder_hidden = encoder(context_tensor, encoder_hidden)\n",
    "#             print(encoder_output.shape,encoder_hidden.shape )\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            for di in range(20):\n",
    "#                 print(\"iterate_over_target {}th time, decoder_input.shape {}\".format(di, decoder_input.shape))\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "#                 print(\"decoder_output.shape {}, decoder_hidden.shape{}\".format(decoder_output.shape, decoder_hidden.shape))\n",
    "                word_index = int(torch.argmax(decoder_output))\n",
    "#                 print(word_index)\n",
    "                output_question += ' ' + index2word[word_index]\n",
    "                if word_index == SOS_token:\n",
    "                    print(\"\\nQUESTION ==> \", output_question)\n",
    "                    break\n",
    "                    \n",
    "predict(context_trial, encoder_no_att, decoder_no_att)        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
