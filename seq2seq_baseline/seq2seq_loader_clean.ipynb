{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install tqdm\n",
    "!pip3 install nltk\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!apt-get install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ИЗМЕНИТЬ ПУТЬ В ЗАВИСИМОСТИ ОТ ТОГО ГДЕ ЗАПУСКАЕМ КОД\n",
    "LOCAL_PATH = \"ctx_quest.csv\"\n",
    "MACHINE_PATH = \"/Users/lilyakhoang/input/question_generation/ctx_quest.csv\"\n",
    "df = pd.read_csv()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потом можете добавить свою предобработку\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_data = []\n",
    "all_text_data.extend(list(df['context']))\n",
    "all_text_data.extend(list(df['question']))\n",
    "all_text_data = list(set(all_text_data))\n",
    "cleaned_text_data = [x for x in all_text_data if 'float' not in str(type(x))]\n",
    "cleaned_text_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(cleaned_text_data):\n",
    "  \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.title('Распределение длин слов в текстах')\n",
    "plt.xlabel('Длина предложения')\n",
    "plt.ylabel('Доля')\n",
    "sns.distplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_threshold = 80\n",
    "lower_threshold = 10\n",
    "\n",
    "correct_percent = len([sent_len for sent_len in lengths \n",
    "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
    "\n",
    "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LENGTH = 80\n",
    "QUESTION_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"/Users/lilyakhoang/input/glove.6B/glove.6B.50d.txt\"\n",
    "this_folder_path = \"glove.6B.50d.txt\"\n",
    "with open(local_path, \"r\") as lines:\n",
    "    for line in lines:\n",
    "      print(line.split()[0], line.split()[0] in word2freq, len(line.split()[1:]))\n",
    "      print(line.split()[1:])\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ЗАПУСТИТЬ ЕСЛИ ИЗ КОЛАБА\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ИЗМЕНИТЬ ПУТЬ В ЗАВИСИМОСТИ ОТ ТОГО ГДЕ ЗАПУСКАЕМ КОД\n",
    "local_path = \"/Users/lilyakhoang/input/glove.6B/glove.6B.50d.txt\"\n",
    "this_folder_path = \"glove.6B.50d.txt\"\n",
    "\n",
    "word2index = {'PAD': 0}\n",
    "vectors = []\n",
    "    \n",
    "with open(local_path, \"r\") as lines:\n",
    "    \n",
    "    embedding_dim = 50\n",
    "    # Zero vector for PAD\n",
    "    vectors.append(np.zeros((1, embedding_dim)))\n",
    "    progress_bar = tqdm(desc='Read word2vec', total=400000)\n",
    "\n",
    "    for line in lines:\n",
    "        current_word = line.split()[0]\n",
    "        if current_word in word2freq:\n",
    "\n",
    "            word2index[current_word] = len(word2index)\n",
    "\n",
    "            # current_vectors = current_parts[-embedding_dim:]\n",
    "            current_vectors = line.split()[1:]\n",
    "            current_vectors = np.array(list(map(float, current_vectors)))\n",
    "            current_vectors = np.expand_dims(current_vectors, 0)\n",
    "\n",
    "            vectors.append(current_vectors)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    vectors = np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_words = [word for word in word2freq if word not in word2index]\n",
    "unk_counts = [word2freq[word] for word in unk_words]\n",
    "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
    "\n",
    "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
    "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
    "\n",
    "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
    "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
    "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
    "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
    "print()\n",
    "print('Топ 5 невошедших слов:')\n",
    "\n",
    "for i in range(5):\n",
    "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, ctx_quest_pairs_list , word2index, context_sequence_length=80, \n",
    "                 question_sequence_length = 20, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.context_sequence_length = context_sequence_length\n",
    "        self.question_sequence_length = question_sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(ctx_quest_pairs_list, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        # Место для вашей предобработки\n",
    "    \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for ctx_quest_pair in data_iterator:\n",
    "            ctx = ctx_quest_pair[0]\n",
    "            quest = ctx_quest_pair[1]\n",
    "\n",
    "            ctx = self.process_text(ctx)\n",
    "            indexed_ctx = self.indexing(ctx)\n",
    "            self.x_data.append(indexed_ctx)\n",
    "\n",
    "            quest = self.process_text(quest)\n",
    "            indexed_quest = self.indexing(quest)\n",
    "            self.y_data.append(indexed_quest)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        indexes = []\n",
    "        for word in tokenized_text:\n",
    "          if word in self.word2index:\n",
    "            indexes.append(self.word2index[word])\n",
    "        return indexes\n",
    "    \n",
    "    def padding(self, sequence, sequence_type):\n",
    "        if sequence_type == 'context':\n",
    "          sequence_length = self.context_sequence_length\n",
    "        elif sequence_type == \"question\":\n",
    "          sequence_length = self.question_sequence_length\n",
    "        else:\n",
    "          raise \"unkown sequence type\"\n",
    "        count = 0 \n",
    "        paded_seq = []\n",
    "        for seq_el in sequence:\n",
    "          paded_seq.append(seq_el)\n",
    "          count += 1\n",
    "          if count >= sequence_length: break\n",
    "        if count < sequence_length:\n",
    "          for ind in range (count, sequence_length):\n",
    "            paded_seq.append(self.pad_index)\n",
    "\n",
    "        return paded_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x, \"context\")\n",
    "        x = torch.Tensor(x).long()\n",
    "\n",
    "        y = self.y_data[idx]\n",
    "        y = self.padding(y, \"question\")\n",
    "        y = torch.Tensor(y).long()\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_answer_pairs = []\n",
    "for ctx, quest in zip(list(df['context']), list(df['question'])):\n",
    "  if 'float' in str(type(ctx)) or 'float' in str(type(quest)):\n",
    "    continue\n",
    "  else:\n",
    "    cont_answer_pairs.append((ctx, quest))\n",
    "len(cont_answer_pairs), cont_answer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WordData(cont_answer_pairs, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=64)\n",
    "for x, y in data_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_p=0.1, max_length=QUESTION_LENGTH, vectors=vectors):#output_size\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.vectors = vectors\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        # self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vectors, device = device))\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "#         self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, 80)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "#         self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, debug = False):\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        if debug == True: \n",
    "            print(\"==forward_decoding_cycle===\")\n",
    "            print(\"input.shape\", input.shape)\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        if debug == True: print(\"embedded[0].shape {}, hidden.shape {}\".format(embedded[0].shape, hidden.shape))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden), 1)), dim=1)\n",
    "        if debug == True: \n",
    "            print(\"attn_weights.shape\",attn_weights.shape,\"encoder_outputs.shape\", encoder_outputs.shape)\n",
    "            print(\"attn_weights.unsqueeze(0).shape\",attn_weights.unsqueeze(0).shape,\"encoder_outputs.unsqueeze(0).shape\", encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        if debug == True: \n",
    "            print(\"output.shape {}, hidden.shape {}\".format(output.shape,hidden.shape ))\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        hidden = hidden.squeeze(1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vectors=vectors):#input_size\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden, debug = False):\n",
    "        if debug == True: \n",
    "            print(\"====ENCODING_FORWARD====\")\n",
    "            print(\"input.shape\", input.shape)\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        if debug == True: \n",
    "            print(\"embedded/output.shape\",embedded.shape,\"hidden.shape\", hidden.shape  )\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 64, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, vectors):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        # self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors))\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, self.vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, debug = False):\n",
    "        if debug == True:\n",
    "          print(\"===FORWARD_DECODER===\")\n",
    "          print(\"input.shape {}, hidden.shape {}\".format(input.shape,hidden.shape ))\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_easy(input_tensor, target_batch_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, ctx_len =SENTENCE_LENGTH, \n",
    "          debug = False):\n",
    "    if debug == True: print(\"target_batch_tensor.shape {}\".format(target_batch_tensor.shape))\n",
    "    \n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_batch_tensor.size(1)\n",
    "    if debug == True: print(\"target_length\", target_length)\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "    \n",
    "\n",
    "    if debug == True: print(\"AFTER_ENCODING , encoder_output.shape{}, encoder_hidden.shape{}\".format(encoder_output.shape, encoder_hidden.shape))\n",
    "    \n",
    "    for batch_element_index in range(64):\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        target_tensor = target_batch_tensor[batch_element_index, :]\n",
    "        if debug == True: \n",
    "            print(\"target_tensor.shape {}, target_tensor {}\".format(target_tensor.shape, target_tensor))\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden[:,batch_element_index,:].unsqueeze(1)\n",
    "        \n",
    "        if debug == True: \n",
    "            print(\"go_to_decoder_with decoder_input{}, decoder_hidden.shape {}\".format(decoder_input, decoder_hidden.shape))\n",
    "\n",
    "\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if debug == True: \n",
    "                print(\"iterate_over_target {}th time, decoder_input.shape {}\".format(di, decoder_input.shape))\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            if debug == True: \n",
    "                print(\"AFTER_DECODER_STEP decoder_output.shape {}, decoder_input.shape {}, decoder_input {}\".format(decoder_output.shape, decoder_input.shape, decoder_input))\n",
    "            target_word = torch.tensor([target_tensor[di]], device=device)\n",
    "            loss += criterion(decoder_output, target_word)\n",
    "            decoder_input = torch.tensor([target_tensor[di]], device=device).unsqueeze(1)  # Teacher forcing\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters_loader(encoder, decoder, epochs = 5, learning_rate=0.01, total_items = len(cont_answer_pairs), debug = False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = []\n",
    "    criterion = nn.NLLLoss()\n",
    "    losses = []\n",
    "    for n_epoch in range(epochs):\n",
    "      progress_bar = tqdm(total=total_items, desc='Epoch {}'.format(n_epoch + 1))\n",
    "      for input_tensor, target_tensor in data_loader:\n",
    "            try:\n",
    "                input_tensor = input_tensor.to(device)\n",
    "                target_tensor = target_tensor.to(device)\n",
    "                if debug == True:print(\"input_tensor.shape\", input_tensor.shape, \"target_tensor.shape\", target_tensor.shape)\n",
    "                loss = train_easy(input_tensor, target_tensor, encoder,\n",
    "                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "                losses.append(loss)\n",
    "                progress_bar.set_postfix(train_loss = np.mean(losses[-100:]))\n",
    "                progress_bar.update(input_tensor.shape[0])\n",
    "                print_loss_total += loss\n",
    "\n",
    "            except:\n",
    "                print(\"smth_wrong_with_tensors\", input_tensor.shape, target_tensor.shape)\n",
    "    print_loss_avg = print_loss_total / total_items\n",
    "    # tqdm.write('Losses: train - {:.3f}, test = {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "    tqdm.write('Losses: train - {:.3f}'.format(print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN WITHOUT ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "# 37487\n",
    "encoder1 = EncoderRNN(hidden_size)\n",
    "encoder1.to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, max_length = MAX_LENGTH, dropout_p=0.1).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, dropout_p=0.1)\n",
    "attn_decoder1 = DecoderRNN(hidden_size, vectors)\n",
    "attn_decoder1.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters_loader(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN WITH ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "encoder1 = EncoderRNN(hidden_size)\n",
    "encoder1.to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, dropout_p=0.1)\n",
    "attn_decoder1.to(device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
