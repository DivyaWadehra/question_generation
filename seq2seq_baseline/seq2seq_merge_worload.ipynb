{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y13XLdrM3-a6"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "6-oqK-1V58mX",
    "outputId": "9ab0968e-0de8-4036-b399-6936b8d84221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvcc: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "QpgI69P07LVV",
    "outputId": "14fba7f1-73bc-42a2-cfbc-e1ad97de185c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-25d92e06-6468-42d4-807a-bfdd776ba450\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-25d92e06-6468-42d4-807a-bfdd776ba450\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ctx_quest.csv to ctx_quest.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "HWrMxZllNKah",
    "outputId": "fe440c2c-6779-4cb3-d9bc-fb2093c512ac"
   },
   "outputs": [],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
    "# !gzip -d cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "MyzKAOsHw-ar",
    "outputId": "7c469796-776a-4e64-9d9f-60e36925ad66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-01 00:20:28--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2019-12-01 00:20:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2019-12-01 00:20:29--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  1.08MB/s    in 16m 16s \n",
      "\n",
      "2019-12-01 00:36:46 (862 KB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "k5gUUelX6C2X",
    "outputId": "08a15c68-abe6-46cb-cc79-6053d9277451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "XEwpa743888_",
    "outputId": "51db2009-9b08-4d45-ff4d-66c2516abde9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1           1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2           2  Managed by her father, Mathew Knowles, the gro...   \n",
       "3           3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4           4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question  \n",
       "0           When did Beyonce start becoming popular?  \n",
       "1  What areas did Beyonce compete in when she was...  \n",
       "2  When did Beyonce leave Destiny's Child and bec...  \n",
       "3      In what city and state did Beyonce  grow up?   \n",
       "4         In which decade did Beyonce become famous?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ctx_quest.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HGptH4olUSe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLjh9LCJlViT"
   },
   "outputs": [],
   "source": [
    "# потом можете добавить свою предобработку\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "KaF-7Hzclaq5",
    "outputId": "fd77d47e-022f-4be2-e1ef-2a0cec7225e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In what country was Flying Fox in Freedom Tree made into a feature film?',\n",
       " ' The actual resistance of the filament is temperature dependent. The cold resistance of tungsten-filament lamps is about 1/15 the hot-filament resistance when the lamp is operating.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_data = []\n",
    "all_text_data.extend(list(df['context']))\n",
    "all_text_data.extend(list(df['question']))\n",
    "all_text_data = list(set(all_text_data))\n",
    "cleaned_text_data = [x for x in all_text_data if 'float' not in str(type(x))]\n",
    "cleaned_text_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DT8QsIc2mpuW",
    "outputId": "66fe66ad-6e65-4850-f967-8513ac259a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'float' in str(type(cleaned_text_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5poc-jRSlXj6",
    "outputId": "c9f746d4-e4a4-406b-a98d-63b53290c34a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144855/144855 [00:05<00:00, 27209.03it/s]\n"
     ]
    }
   ],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(cleaned_text_data):\n",
    "  \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4dgeEr2mtgy1",
    "outputId": "942a51b2-3cee-4b37-df13-9fe402b0c15f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mLKSubhpkki"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ipxRNZJCpabI",
    "outputId": "fffe2a02-c9fb-47d1-8c11-e3bcb91463de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x133940dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.title('Распределение длин слов в текстах')\n",
    "plt.xlabel('Длина предложения')\n",
    "plt.ylabel('Доля')\n",
    "sns.distplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "gAIhoDWlpe1e",
    "outputId": "3ec51f51-3a91-479b-fa38-159f912d7958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36213.75\n",
      "108641.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 62)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(lengths)*0.25)\n",
    "print(len(lengths)*0.75)\n",
    "sorted(lengths)[36213] , sorted(lengths)[108641] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2CaHFCjkqQyG",
    "outputId": "10a37b63-9689-4d02-9a0d-5bbc2eafcaca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66.57 % наших текстов входят в промежуток от 10 до 80 слов'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_threshold = 80\n",
    "lower_threshold = 10\n",
    "\n",
    "correct_percent = len([sent_len for sent_len in lengths \n",
    "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
    "\n",
    "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBZgFH81SFoK"
   },
   "outputs": [],
   "source": [
    "SENTENCE_LENGTH = 80\n",
    "QUESTION_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Ftv_s1-wy_XD",
    "outputId": "546bbe04-7c07-4fe4-85ca-eb77a9e4fe61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the True 50\n",
      "['0.418', '0.24968', '-0.41242', '0.1217', '0.34527', '-0.044457', '-0.49688', '-0.17862', '-0.00066023', '-0.6566', '0.27843', '-0.14767', '-0.55677', '0.14658', '-0.0095095', '0.011658', '0.10204', '-0.12792', '-0.8443', '-0.12181', '-0.016801', '-0.33279', '-0.1552', '-0.23131', '-0.19181', '-1.8823', '-0.76746', '0.099051', '-0.42125', '-0.19526', '4.0071', '-0.18594', '-0.52287', '-0.31681', '0.00059213', '0.0074449', '0.17778', '-0.15897', '0.012041', '-0.054223', '-0.29871', '-0.15749', '-0.34758', '-0.045637', '-0.44251', '0.18785', '0.0027849', '-0.18411', '-0.11514', '-0.78581']\n"
     ]
    }
   ],
   "source": [
    "with open(\"glove.6B.50d.txt\", \"r\") as lines:\n",
    "    for line in lines:\n",
    "      print(line.split()[0], line.split()[0] in word2freq, len(line.split()[1:]))\n",
    "      print(line.split()[1:])\n",
    "      break\n",
    "    \n",
    "    # w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "    #        for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98_duPhfy0Oi"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "#     w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "#            for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P9pH7FHdsw8F",
    "outputId": "8de5320f-b78c-4346-f16f-c68039c208e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read word2vec: 100%|██████████| 400000/400000 [00:04<00:00, 95373.91it/s] \n"
     ]
    }
   ],
   "source": [
    "word2index = {'PAD': 0}\n",
    "vectors = []\n",
    "    \n",
    "# word2vec_file = open('cc.ru.300.vec')\n",
    "with open(\"glove.6B.50d.txt\", \"r\") as lines:\n",
    "    \n",
    "    # n_words, embedding_dim = word2vec_file.readline().split()\n",
    "    # n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
    "    embedding_dim = 50\n",
    "    # Zero vector for PAD\n",
    "    vectors.append(np.zeros((1, embedding_dim)))\n",
    "    progress_bar = tqdm(desc='Read word2vec', total=400000)\n",
    "\n",
    "    # while True:\n",
    "\n",
    "    #     line = word2vec_file.readline().strip()\n",
    "\n",
    "    #     if not line:\n",
    "    #         break\n",
    "            \n",
    "        # current_parts = line.split()\n",
    "\n",
    "        # current_word = ' '.join(current_parts[:-embedding_dim])\n",
    "    for line in lines:\n",
    "        current_word = line.split()[0]\n",
    "        if current_word in word2freq:\n",
    "\n",
    "            word2index[current_word] = len(word2index)\n",
    "\n",
    "            # current_vectors = current_parts[-embedding_dim:]\n",
    "            current_vectors = line.split()[1:]\n",
    "            current_vectors = np.array(list(map(float, current_vectors)))\n",
    "            current_vectors = np.expand_dims(current_vectors, 0)\n",
    "\n",
    "            vectors.append(current_vectors)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # word2vec_file.close()\n",
    "\n",
    "    vectors = np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ApRgFQMPs1Lw",
    "outputId": "99b7e480-7136-45d8-d645-05488815e33a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64902, 80148)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index), len(word2freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "20szKGKjtV_H",
    "outputId": "ee1c0930-d66d-44d5-f8e9-bcb599c1577b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 1.31 % слов в датасете\n",
      "Количество неизвестных слов 15247 из 80148, то есть 19.02 % уникальных слов в словаре\n",
      "В среднем каждое встречается 4.49 раз\n",
      "\n",
      "Топ 5 невошедших слов:\n",
      "), с количеством вхождениий - 8360\n",
      "). с количеством вхождениий - 6262\n",
      "\". с количеством вхождениий - 2903\n",
      "\", с количеством вхождениий - 2574\n",
      ".\" с количеством вхождениий - 2351\n"
     ]
    }
   ],
   "source": [
    "unk_words = [word for word in word2freq if word not in word2index]\n",
    "unk_counts = [word2freq[word] for word in unk_words]\n",
    "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
    "\n",
    "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
    "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
    "\n",
    "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
    "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
    "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
    "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
    "print()\n",
    "print('Топ 5 невошедших слов:')\n",
    "\n",
    "for i in range(5):\n",
    "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQwTHuEvJkZ5"
   },
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, ctx_quest_pairs_list , word2index, context_sequence_length=80, \n",
    "                 question_sequence_length = 20, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.context_sequence_length = context_sequence_length\n",
    "        self.question_sequence_length = question_sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(ctx_quest_pairs_list, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        # Место для вашей предобработки\n",
    "    \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for ctx_quest_pair in data_iterator:\n",
    "            ctx = ctx_quest_pair[0]\n",
    "            quest = ctx_quest_pair[1]\n",
    "\n",
    "            ctx = self.process_text(ctx)\n",
    "            indexed_ctx = self.indexing(ctx)\n",
    "            self.x_data.append(indexed_ctx)\n",
    "\n",
    "            quest = self.process_text(quest)\n",
    "            indexed_quest = self.indexing(quest)\n",
    "            self.y_data.append(indexed_quest)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        indexes = []\n",
    "        for word in tokenized_text:\n",
    "          if word in self.word2index:\n",
    "            indexes.append(self.word2index[word])\n",
    "        return indexes\n",
    "    \n",
    "    def padding(self, sequence, sequence_type):\n",
    "        if sequence_type == 'context':\n",
    "          sequence_length = self.context_sequence_length\n",
    "        elif sequence_type == \"question\":\n",
    "          sequence_length = self.question_sequence_length\n",
    "        else:\n",
    "          raise \"unkown sequence type\"\n",
    "        count = 0 \n",
    "        paded_seq = []\n",
    "        for seq_el in sequence:\n",
    "          paded_seq.append(seq_el)\n",
    "          count += 1\n",
    "          if count >= sequence_length: break\n",
    "        if count < sequence_length:\n",
    "          for ind in range (count, sequence_length):\n",
    "            paded_seq.append(self.pad_index)\n",
    "\n",
    "        return paded_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x, \"context\")\n",
    "        x = torch.Tensor(x).long()\n",
    "\n",
    "        y = self.y_data[idx]\n",
    "        y = self.padding(y, \"question\")\n",
    "        y = torch.Tensor(y).long()\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "l5IiRUrsKXwL",
    "outputId": "492e35ef-df0b-47a8-b572-2fbfdcbeae11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86610,\n",
       " (\"Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time.\",\n",
       "  'When did Beyonce start becoming popular?'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_answer_pairs = []\n",
    "for ctx, quest in zip(list(df['context']), list(df['question'])):\n",
    "  if 'float' in str(type(ctx)) or 'float' in str(type(quest)):\n",
    "    continue\n",
    "  else:\n",
    "    cont_answer_pairs.append((ctx, quest))\n",
    "len(cont_answer_pairs), cont_answer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "colab_type": "code",
    "id": "GV4VK_S9MVVb",
    "outputId": "3feaa968-d40f-4319-f429-cb18daf6e100"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec764938d1cf41fd8f69259bda1c1cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading data', max=86610, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = WordData(cont_answer_pairs, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "5w_84zZLMzAM",
    "outputId": "b5b3cd8c-f909-4653-bfa7-5491e8faa95a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([33972, 33404, 16932,    11,  3127,   270,  8242,    11, 36992,    11,\n",
       "           200,    24,    23,   375,   437,   405,     2,  2852,    24,    14,\n",
       "            28,   137,  2195,     2,  9315,     2,   380,  1913,     6,  2844,\n",
       "             3,   375,     6,  1059,     7,  1971,     2,   736,     2,    66,\n",
       "          1767,     7,   904,  4027,     6,  5264,  5557,    19,     8,   951,\n",
       "             2,     6,   480,     5,  3101,     7,     1,   284,  2222,    19,\n",
       "           406,  2195,     4,  1886,  1146,  1535,  1728,    11,   126,  9697,\n",
       "            56,  1513,   951,     3,  1743,    21,    69,   623,     2, 23818]),\n",
       " tensor([   60,   116, 25922,   460,  1642,   803,   185,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "h1bFf1IAOTkw",
    "outputId": "04bb16d9-5a7f-4c34-b490-8ae3f3502cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 80]) torch.Size([64, 20])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=64)\n",
    "for x, y in data_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecoderRNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, hidden_size, output_size):\n",
    "#         super(DecoderRNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         output = self.embedding(input)\n",
    "#         output = F.relu(output)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         output = self.softmax(self.out(output[0]))\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ochiHaqZ3-cG"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vectors=vectors):#input_size\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.vectors, device = device))\n",
    "\n",
    "        # self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden, debug = False):\n",
    "        if debug == True: \n",
    "            print(\"====ENCODING_FORWARD====\")\n",
    "            print(\"input.shape\", input.shape)\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        if debug == True: \n",
    "            print(\"embedded/output.shape\",embedded.shape,\"hidden.shape\", hidden.shape  )\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 64, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXYS842I3-cQ"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_p=0.1, max_length=QUESTION_LENGTH, vectors=vectors):#output_size\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.vocab_size, self.embedding_dim = vectors.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vectors, device = device))\n",
    "#         self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, 80)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "#         self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, debug = False):\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        if debug == True: \n",
    "            print(\"==forward_decoding_cycle===\")\n",
    "            print(\"input.shape\", input.shape)\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        if debug == True: print(\"embedded[0].shape {}, hidden.shape {}\".format(embedded[0].shape, hidden.shape))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden), 1)), dim=1)\n",
    "        if debug == True: \n",
    "            print(\"attn_weights.shape\",attn_weights.shape,\"encoder_outputs.shape\", encoder_outputs.shape)\n",
    "            print(\"attn_weights.unsqueeze(0).shape\",attn_weights.unsqueeze(0).shape,\"encoder_outputs.unsqueeze(0).shape\", encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        if debug == True: \n",
    "            print(\"output.shape {}, hidden.shape {}\".format(output.shape,hidden.shape ))\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        hidden = hidden.squeeze(1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiVkIVcN3-ca"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_batch_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, ctx_len =SENTENCE_LENGTH, \n",
    "          debug = False):\n",
    "    \n",
    "    if debug == True: print(\"target_batch_tensor.shape {}\".format(target_batch_tensor.shape))\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_batch_tensor.size(1)\n",
    "    if debug == True: print(\"target_length\", target_length)\n",
    "\n",
    "#     encoder_outputs = torch.zeros(ctx_len, encoder.hidden_size, device=device)\n",
    "#     print(\"encoder_outputs.shape\", encoder_outputs.shape)\n",
    "  \n",
    "    loss = 0\n",
    "#     print(\"input_length is\", input_length)\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "    \n",
    "#     for ei in range(input_length):\n",
    "# #         print(\"ei\", ei)\n",
    "#         print(\"input_tensor[ei].shape\",input_tensor[ei].shape, \"encoder_hidden.shape\", encoder_hidden.shape)\n",
    "#         encoder_output, encoder_hidden = encoder(\n",
    "#             input_tensor[ei], encoder_hidden)\n",
    "#         encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    if debug == True: print(\"AFTER_ENCODING , encoder_output.shape{}, encoder_hidden.shape{}\".format(encoder_output.shape, encoder_hidden.shape))\n",
    "    \n",
    "    for batch_element_index in range(64):\n",
    "        target_tensor = target_batch_tensor[batch_element_index, :]\n",
    "        if debug == True: \n",
    "            print(\"target_tensor.shape {}, target_tensor {}\".format(target_tensor.shape, target_tensor))\n",
    "#         target_tensor = target_tensor.unsqueeze(-1)\n",
    "#         print(\"target_tensor.shape {} after unsqueeze\".format(target_tensor.shape))\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden[:,batch_element_index,:]\n",
    "        \n",
    "        encoder_outputs = encoder_output[batch_element_index,:,:]\n",
    "        if debug == True: print(\"go_to_decoder_with decoder_input{}, decoder_hidden.shape {}, encoder_outputs.shape{}\".format(decoder_input, decoder_hidden.shape, encoder_outputs.shape))\n",
    "\n",
    "#         use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        use_teacher_forcing = True\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                if debug == True: \n",
    "                    print(\"iterate_over_target {}th time, decoder_input.shape {}\".format(di, decoder_input.shape))\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                if debug == True: \n",
    "                    print(\"AFTER_DECODER_STEP decoder_output.shape {}, decoder_input.shape {}, decoder_input {}\".format(decoder_output.shape, decoder_input.shape, decoder_input))\n",
    "#                 decoder_input = torch.tensor([decoder_input], device=device)\n",
    "                target_word = torch.tensor([target_tensor[di]], device=device)\n",
    "                loss += criterion(decoder_output, target_word)\n",
    "                if debug == True: print(\"loss\", loss)\n",
    "                decoder_input = torch.tensor([target_tensor[di]], device=device).unsqueeze(1)  # Teacher forcing\n",
    "#                 decoder_input = target_tensor[di]\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor[di])\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nM8cfTt3-cf"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3mhLPgiO3Jk"
   },
   "outputs": [],
   "source": [
    "def trainIters_loader(encoder, decoder, epochs = 5, learning_rate=0.01, total_items = len(cont_answer_pairs), debug = False):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = []\n",
    "    criterion = nn.NLLLoss()\n",
    "    losses = []\n",
    "    for n_epoch in range(epochs):\n",
    "      progress_bar = tqdm(total=total_items, desc='Epoch {}'.format(n_epoch + 1))\n",
    "      for input_tensor, target_tensor in data_loader:\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "            if debug == True:print(\"input_tensor.shape\", input_tensor.shape, \"target_tensor.shape\", target_tensor.shape)\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            losses.append(loss)\n",
    "            progress_bar.set_postfix(train_loss = np.mean(losses[-100:]))\n",
    "#             print(\"should_update_by {}\".format(input_tensor.shape[0]))\n",
    "            progress_bar.update(input_tensor.shape[0])\n",
    "            print_loss_total += loss\n",
    "          # plot_loss_total += loss\n",
    "\n",
    "          # if iter % print_every == 0:\n",
    "          #     print_loss_avg = print_loss_total / print_every\n",
    "          #     print_loss_total = 0\n",
    "          #     print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "          #                                 iter, iter / n_iters * 100, print_loss_avg))\n",
    "          #     # evaluateRandomly(encoder, decoder, n = 5)\n",
    "          # if iter % plot_every == 0:\n",
    "          #     plot_loss_avg = plot_loss_total / plot_every\n",
    "          #     plot_losses.append(plot_loss_avg)\n",
    "          #     plot_loss_total = 0\n",
    "          #     showPlot(plot_losses)\n",
    "    print_loss_avg = print_loss_total / total_items\n",
    "    # tqdm.write('Losses: train - {:.3f}, test = {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "    tqdm.write('Losses: train - {:.3f}'.format(print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e70e9661d34dfcae66c25c23d94865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=86610, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-2b61f0609fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainIters_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-191-33e103348f17>\u001b[0m in \u001b[0;36mtrainIters_loader\u001b[0;34m(encoder, decoder, epochs, learning_rate, total_items, debug)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_tensor.shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target_tensor.shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                       decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-195-89c30bdfbb51>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_batch_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, ctx_len, debug)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "# 37487\n",
    "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "encoder1 = EncoderRNN(hidden_size).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, max_length = MAX_LENGTH, dropout_p=0.1).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters_loader(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3cB9i2H3-cp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uekPvILp3-cu"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-d73782908d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length, device=device)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoqK4Vos3-cy"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dbX_6E8uWL2u",
    "outputId": "c6427601-905c-4322-dbcb-f450001c814f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "colab_type": "code",
    "id": "lj9Q8GF73-dC",
    "outputId": "9fbe5364-c133-4f14-f9cc-7ce4805d3d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> the cemetery originated when the englishman mr . thomas samuel hood purchased a plot of land in the name of the english residents in .\n",
      "= when did mr . thomas samuel hood purchase a plot of land at the british cemetery montevideo ?\n",
      "< when did the did of the ? ? ? ? <EOS>\n",
      "\n",
      "> asphalt emulsions contain up to asphalt bitumen and typically less than . chemical additives .\n",
      "= what percentage of bitumen is found in bitumen water emulsions ?\n",
      "< what do the for for the ? <EOS>\n",
      "\n",
      "> according to the china national space administration the development of the system would be carried out in three steps \n",
      "= the china national space administration said the satellite navigation system would be developed in how many steps ?\n",
      "< what many the the of the the <EOS>\n",
      "\n",
      "> duplications play a major role in shaping the genome .\n",
      "= what type of generation of genetic material has a big part in making the genome what it is ?\n",
      "< what type of a the the <EOS>\n",
      "\n",
      ">  an example of a perdurantist is david lewis . \n",
      "= who is an example of a perdurantist ?\n",
      "< what is the the to the <EOS>\n",
      "\n",
      "> the nocturnes are more structured and of greater emotional depth than those of field whom chopin met in .\n",
      "= chopin s nocturnes were more structured than who ?\n",
      "< how many the the of the <EOS>\n",
      "\n",
      "> portuguese guinea was known as the slave coast as it was a major area for the exportation of african slaves by europeans to the western hemisphere .\n",
      "= what area was known as the slave coast ?\n",
      "< what was the the of the ? ? ? <EOS>\n",
      "\n",
      ">  . of new yorkers commuted to work in using mass transit .\n",
      "= in what percentage of new york residents used mass transit to get to work ?\n",
      "< what is the new of to <EOS>\n",
      "\n",
      "> ipod batteries are not designed to be removed or replaced by the user although some users have been able to open the case themselves usually following instructions from third party vendors of ipod replacement batteries .\n",
      "= whose directions can be followed to interact with ipod batteries ?\n",
      "< who are the the of to ? <EOS>\n",
      "\n",
      "> spayed female dogs are less likely to develop some forms of cancer affecting mammary glands ovaries and other reproductive organs .\n",
      "= female dogs are less likely to develop cancer if what happens ?\n",
      "< what is the to of the to ? <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
