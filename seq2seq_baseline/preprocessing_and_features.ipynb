{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "from deeppavlov import configs, build_model\n",
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    data = json.load(f)\n",
    "    data_par = json_normalize(data=data['data'], record_path=['paragraphs'], meta=['title'])\n",
    "    \n",
    "    return data_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('squad/train-v2.0.json')\n",
    "squad_train = load_json(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('squad/dev-v2.0.json')\n",
    "squad_dev = load_json(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(data_par):\n",
    "    new_df = pd.DataFrame()\n",
    "    for idx, listOfDicts in data_par[['qas']].itertuples():\n",
    "        qas = pd.DataFrame.from_dict(listOfDicts)\n",
    "        qas['title'] = data_par['title'][idx]\n",
    "        qas['context'] = data_par['context'][idx]\n",
    "        qas['answer'] = ''\n",
    "        qas['answer_start'] = ''\n",
    "        for ind, answer in qas[['answers']].itertuples():\n",
    "            if answer == []:\n",
    "                answer = qas['plausible_answers'][ind]\n",
    "            try:\n",
    "                dic = random.sample(answer, 1)[0]\n",
    "            except ValueError:\n",
    "                pass\n",
    "            qas['answer'][ind] = dic.get('text')\n",
    "            qas['answer_start'][ind] = dic.get('answer_start')\n",
    "        new_df = new_df.append(qas)\n",
    "\n",
    "    new_df = new_df.drop('answers', axis=1)\n",
    "    new_df = new_df.drop('plausible_answers', axis=1)   \n",
    "    new_df = new_df.drop('id', axis=1)\n",
    "    new_df = new_df.reset_index()\n",
    "    new_df = new_df.drop('index', axis=1)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squad_train = json_to_df(squad_train)\n",
    "print(len(squad_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>context</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Destiny's Child</td>\n",
       "      <td>320</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>In what R&amp;B group was she the lead singer?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dangerously in Love</td>\n",
       "      <td>505</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>What album made her a worldwide known artist?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mathew Knowles</td>\n",
       "      <td>360</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>When did Beyoncé rise to fame?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lead singer</td>\n",
       "      <td>290</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                answer answer_start  \\\n",
       "0    in the late 1990s          269   \n",
       "1  singing and dancing          207   \n",
       "2                 2003          526   \n",
       "3       Houston, Texas          166   \n",
       "4           late 1990s          276   \n",
       "5      Destiny's Child          320   \n",
       "6  Dangerously in Love          505   \n",
       "7       Mathew Knowles          360   \n",
       "8           late 1990s          276   \n",
       "9          lead singer          290   \n",
       "\n",
       "                                             context  is_impossible  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "5  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "6  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "7  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "8  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "9  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "\n",
       "                                            question    title  \n",
       "0           When did Beyonce start becoming popular?  Beyoncé  \n",
       "1  What areas did Beyonce compete in when she was...  Beyoncé  \n",
       "2  When did Beyonce leave Destiny's Child and bec...  Beyoncé  \n",
       "3      In what city and state did Beyonce  grow up?   Beyoncé  \n",
       "4         In which decade did Beyonce become famous?  Beyoncé  \n",
       "5         In what R&B group was she the lead singer?  Beyoncé  \n",
       "6      What album made her a worldwide known artist?  Beyoncé  \n",
       "7             Who managed the Destiny's Child group?  Beyoncé  \n",
       "8                     When did Beyoncé rise to fame?  Beyoncé  \n",
       "9     What role did Beyoncé have in Destiny's Child?  Beyoncé  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11873\n"
     ]
    }
   ],
   "source": [
    "squad_dev = json_to_df(squad_dev)\n",
    "print(len(squad_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>France</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>10th</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who gave their name to Normandy in the 1000's ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Normans</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is France a region of?</td>\n",
       "      <td>True</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Normandy</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who did King Charles III swear fealty to?</td>\n",
       "      <td>True</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When did the Frankish identity emerge?</td>\n",
       "      <td>True</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>10th century</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Who was the duke in the battle of Hastings?</td>\n",
       "      <td>False</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Norman dynasty had a major political, cult...</td>\n",
       "      <td>William the Conqueror</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  is_impossible    title  \\\n",
       "0               In what country is Normandy located?          False  Normans   \n",
       "1                 When were the Normans in Normandy?          False  Normans   \n",
       "2      From which countries did the Norse originate?          False  Normans   \n",
       "3                          Who was the Norse leader?          False  Normans   \n",
       "4  What century did the Normans first gain their ...          False  Normans   \n",
       "5  Who gave their name to Normandy in the 1000's ...           True  Normans   \n",
       "6                        What is France a region of?           True  Normans   \n",
       "7          Who did King Charles III swear fealty to?           True  Normans   \n",
       "8             When did the Frankish identity emerge?           True  Normans   \n",
       "9        Who was the duke in the battle of Hastings?          False  Normans   \n",
       "\n",
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "3  The Normans (Norman: Nourmands; French: Norman...   \n",
       "4  The Normans (Norman: Nourmands; French: Norman...   \n",
       "5  The Normans (Norman: Nourmands; French: Norman...   \n",
       "6  The Normans (Norman: Nourmands; French: Norman...   \n",
       "7  The Normans (Norman: Nourmands; French: Norman...   \n",
       "8  The Normans (Norman: Nourmands; French: Norman...   \n",
       "9  The Norman dynasty had a major political, cult...   \n",
       "\n",
       "                        answer answer_start  \n",
       "0                       France          159  \n",
       "1      10th and 11th centuries           94  \n",
       "2  Denmark, Iceland and Norway          256  \n",
       "3                        Rollo          308  \n",
       "4                         10th          671  \n",
       "5                      Normans            4  \n",
       "6                     Normandy          137  \n",
       "7                        Rollo          308  \n",
       "8                 10th century          671  \n",
       "9        William the Conqueror         1022  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SberQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sberquad/train-v1.1.json')\n",
    "sberquad_train = load_json(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sberquad/dev-v1.1.json')\n",
    "sberquad_dev = load_json(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df_sber(data_par):\n",
    "    new_df = pd.DataFrame({'context': data_par['context']})\n",
    "    new_df['question'] = ''\n",
    "    new_df['answer'] = ''\n",
    "    new_df['answer_start'] = ''\n",
    "    \n",
    "    for idx, listOfDicts in data_par[['qas']].itertuples():\n",
    "        dic = listOfDicts[0]\n",
    "        new_df['question'][idx] = dic.get('question')\n",
    "        answer = dic.get('answers')[0]\n",
    "        new_df['answer'][idx] = answer.get('text')\n",
    "        new_df['answer_start'][idx] = answer.get('answer_start')\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45328\n"
     ]
    }
   ],
   "source": [
    "sberquad_train = json_to_df_sber(sberquad_train)\n",
    "print(len(sberquad_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В допетровское время искусство в России имело ...</td>\n",
       "      <td>Чем на Руси ограничивались проявления пластики?</td>\n",
       "      <td>литьем небольших крестов, образов-складней, вы...</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По данным рейтинга Top 100 самых филиальных ба...</td>\n",
       "      <td>Какое место занимает УБРиР по даным рейтинга T...</td>\n",
       "      <td>9 место</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Смарт-стекло — современный собирательный терми...</td>\n",
       "      <td>Какие свойства в общем способно изменять смарт...</td>\n",
       "      <td>оптические</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Во время интервенции в Россию Речи Посполитой ...</td>\n",
       "      <td>Как звали воеводу Дорогобужа, который сдал гор...</td>\n",
       "      <td>Иван Ададуров</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В начале 1823 года Грибоедов на время покинул ...</td>\n",
       "      <td>В каком году Грибоедов написал водевиль Кто бр...</td>\n",
       "      <td>1823</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Так как некоторые из римских месяцев были назв...</td>\n",
       "      <td>Кто предполагал существование гипотетического ...</td>\n",
       "      <td>Якоб Гримм</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Важным инструментом сохранения редких видов жи...</td>\n",
       "      <td>в какое приложение Бернской конвенции занесён ...</td>\n",
       "      <td>приложение II</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Постоянное городское население города Сочи — 4...</td>\n",
       "      <td>Какое место по числу жителей занимал Сочи сред...</td>\n",
       "      <td>3-е место</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>В 1980-х годах, с развитием панк-рока и появле...</td>\n",
       "      <td>Как звали гитариста группы конца 70-х Joy Divi...</td>\n",
       "      <td>Бернард Самнер</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Находясь в общем русле крымской истории, Феодо...</td>\n",
       "      <td>Насколько попытка контрнаступления второго Фед...</td>\n",
       "      <td>на несколько дней</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  В допетровское время искусство в России имело ...   \n",
       "1  По данным рейтинга Top 100 самых филиальных ба...   \n",
       "2  Смарт-стекло — современный собирательный терми...   \n",
       "3  Во время интервенции в Россию Речи Посполитой ...   \n",
       "4  В начале 1823 года Грибоедов на время покинул ...   \n",
       "5  Так как некоторые из римских месяцев были назв...   \n",
       "6  Важным инструментом сохранения редких видов жи...   \n",
       "7  Постоянное городское население города Сочи — 4...   \n",
       "8  В 1980-х годах, с развитием панк-рока и появле...   \n",
       "9  Находясь в общем русле крымской истории, Феодо...   \n",
       "\n",
       "                                            question  \\\n",
       "0    Чем на Руси ограничивались проявления пластики?   \n",
       "1  Какое место занимает УБРиР по даным рейтинга T...   \n",
       "2  Какие свойства в общем способно изменять смарт...   \n",
       "3  Как звали воеводу Дорогобужа, который сдал гор...   \n",
       "4  В каком году Грибоедов написал водевиль Кто бр...   \n",
       "5  Кто предполагал существование гипотетического ...   \n",
       "6  в какое приложение Бернской конвенции занесён ...   \n",
       "7  Какое место по числу жителей занимал Сочи сред...   \n",
       "8  Как звали гитариста группы конца 70-х Joy Divi...   \n",
       "9  Насколько попытка контрнаступления второго Фед...   \n",
       "\n",
       "                                              answer answer_start  \n",
       "0  литьем небольших крестов, образов-складней, вы...          583  \n",
       "1                                            9 место          115  \n",
       "2                                         оптические          205  \n",
       "3                                      Иван Ададуров          287  \n",
       "4                                               1823            9  \n",
       "5                                         Якоб Гримм          535  \n",
       "6                                      приложение II          183  \n",
       "7                                          3-е место          408  \n",
       "8                                     Бернард Самнер          230  \n",
       "9                                  на несколько дней          416  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sberquad_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036\n"
     ]
    }
   ],
   "source": [
    "sberquad_dev = json_to_df_sber(sberquad_dev)\n",
    "print(len(sberquad_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В Миссолонги Байрон заболел лихорадкой, продол...</td>\n",
       "      <td>Чем заболел Байрон в Миссолонги?</td>\n",
       "      <td>лихорадкой</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>От излишней потери тепла млекопитающих предохр...</td>\n",
       "      <td>Как отводятся излишки тепла у млекопитающих?</td>\n",
       "      <td>потоотделением</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Хромосомные перестройки (хромосомные аберрации...</td>\n",
       "      <td>Что нарушают хромосомные аберрации?</td>\n",
       "      <td>Структуру хромосом.</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Первый в мире городской автобус с двигателем в...</td>\n",
       "      <td>В каком городе первый в мире городской автобус...</td>\n",
       "      <td>в Лондоне</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Фродом являются также и операции с поддельными...</td>\n",
       "      <td>В каком режиме проходят подлимитные операции?</td>\n",
       "      <td>в режиме офлайн</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Слоговое письмо представляет собой набор письм...</td>\n",
       "      <td>Находит ли отражение в алфавите фонетическая с...</td>\n",
       "      <td>не находит</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Весной 1890 года художник перебрался в Овер-сю...</td>\n",
       "      <td>Каким стал стиль последних работ художника?</td>\n",
       "      <td>нервным и гнетущим</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>В 2008 году родилось 1147 человек у граждан Шв...</td>\n",
       "      <td>Сколько человек родилось в 2008 году у граждан...</td>\n",
       "      <td>1147 человек</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Иногда говорят о возможности провести GNU GPL ...</td>\n",
       "      <td>Какая статья и пункт дает возможность статья д...</td>\n",
       "      <td>пункт 2 статьи 434</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Первым пособием по товароведению в России обыч...</td>\n",
       "      <td>Какими русскими купцами был накоплен значимый ...</td>\n",
       "      <td>купцами-новгородцами</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  В Миссолонги Байрон заболел лихорадкой, продол...   \n",
       "1  От излишней потери тепла млекопитающих предохр...   \n",
       "2  Хромосомные перестройки (хромосомные аберрации...   \n",
       "3  Первый в мире городской автобус с двигателем в...   \n",
       "4  Фродом являются также и операции с поддельными...   \n",
       "5  Слоговое письмо представляет собой набор письм...   \n",
       "6  Весной 1890 года художник перебрался в Овер-сю...   \n",
       "7  В 2008 году родилось 1147 человек у граждан Шв...   \n",
       "8  Иногда говорят о возможности провести GNU GPL ...   \n",
       "9  Первым пособием по товароведению в России обыч...   \n",
       "\n",
       "                                            question                answer  \\\n",
       "0                   Чем заболел Байрон в Миссолонги?            лихорадкой   \n",
       "1       Как отводятся излишки тепла у млекопитающих?        потоотделением   \n",
       "2                Что нарушают хромосомные аберрации?   Структуру хромосом.   \n",
       "3  В каком городе первый в мире городской автобус...             в Лондоне   \n",
       "4      В каком режиме проходят подлимитные операции?       в режиме офлайн   \n",
       "5  Находит ли отражение в алфавите фонетическая с...            не находит   \n",
       "6        Каким стал стиль последних работ художника?    нервным и гнетущим   \n",
       "7  Сколько человек родилось в 2008 году у граждан...          1147 человек   \n",
       "8  Какая статья и пункт дает возможность статья д...    пункт 2 статьи 434   \n",
       "9  Какими русскими купцами был накоплен значимый ...  купцами-новгородцами   \n",
       "\n",
       "  answer_start  \n",
       "0           28  \n",
       "1          132  \n",
       "2           74  \n",
       "3          103  \n",
       "4          455  \n",
       "5          368  \n",
       "6          232  \n",
       "7           21  \n",
       "8          558  \n",
       "9          245  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sberquad_dev.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очистка ответов от пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(answer):\n",
    "    answer = answer.strip(string.punctuation)\n",
    "    answer = answer.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_dev['answer'] = sberquad_dev['answer'].apply(lambda x: clean_answer(x))\n",
    "sberquad_train['answer'] = sberquad_train['answer'].apply(lambda x: clean_answer(x))\n",
    "squad_dev['answer'] = squad_dev['answer'].apply(lambda x: clean_answer(x))\n",
    "squad_train['answer'] = squad_train['answer'].apply(lambda x: clean_answer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_en(text, answer, answer_start, nlp):\n",
    "    \n",
    "    right = text[0:answer_start]\n",
    "    answer = text[answer_start:answer_start+len(answer)+1]\n",
    "    left = text[answer_start+len(answer)+1:len(text)+1]    \n",
    "    \n",
    "    pos = []\n",
    "    ner = []\n",
    "    case = []\n",
    "    bio = []\n",
    "    tokenized = []\n",
    "    \n",
    "    right_doc = nlp(right)\n",
    "    answer_doc = nlp(answer)\n",
    "    left_doc = nlp(left)\n",
    "    \n",
    "    for token in right_doc:\n",
    "        if token.text != '' and not token.text.isspace():\n",
    "            tokenized.append(token.text.lower())\n",
    "            pos.append(token.pos_)\n",
    "\n",
    "            if token.ent_type_ == '':\n",
    "                ner.append('O')\n",
    "            else:\n",
    "                ner.append(token.ent_type_)\n",
    "\n",
    "            if token.text[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            bio.append('O')\n",
    "    \n",
    "    for token in answer_doc:\n",
    "        if token.text != '' and not token.text.isspace():\n",
    "            tokenized.append(token.text.lower())\n",
    "            pos.append(token.pos_)\n",
    "\n",
    "            if token.ent_type_ == '':\n",
    "                ner.append('O')\n",
    "            else:\n",
    "                ner.append(token.ent_type_)\n",
    "\n",
    "            if token.text[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            if token.i == 0:\n",
    "                bio.append('B')\n",
    "            else:\n",
    "                bio.append('I')\n",
    "    \n",
    "    for token in left_doc:\n",
    "        if token.text != '' and not token.text.isspace():\n",
    "            tokenized.append(token.text.lower())\n",
    "            pos.append(token.pos_)\n",
    "\n",
    "            if token.ent_type_ == '':\n",
    "                ner.append('O')\n",
    "            else:\n",
    "                ner.append(token.ent_type_)\n",
    "\n",
    "            if token.text[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            bio.append('O')\n",
    "                \n",
    "    return (' '.join(pos)), (' '.join(ner)), (' '.join(case)), (' '.join(bio)), (' '.join(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev['POS'] = ''\n",
    "squad_dev['NER'] = ''\n",
    "squad_dev['case'] = ''\n",
    "squad_dev['BIO'] = ''\n",
    "for idx, text, answer, answer_start in squad_dev[['context', 'answer', 'answer_start']].itertuples():\n",
    "    squad_dev['POS'][idx], squad_dev['NER'][idx], squad_dev['case'][idx], squad_dev['BIO'][idx], squad_dev['context'][idx] = features_en(text, answer, answer_start, nlp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    doc = nlp(text)\n",
    "    tokenized = [token.text.lower() for token in doc]\n",
    "    \n",
    "    return ' '.join(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev['question'] = squad_dev['question'].apply(lambda x: tokenize_en(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "      <th>case</th>\n",
       "      <th>BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in what country is normandy located ?</td>\n",
       "      <td>the normans ( norman : nourmands ; french : no...</td>\n",
       "      <td>DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...</td>\n",
       "      <td>O NORP O PERSON O PERSON O NORP O O O LANGUAGE...</td>\n",
       "      <td>UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when were the normans in normandy ?</td>\n",
       "      <td>the normans ( norman : nourmands ; french : no...</td>\n",
       "      <td>DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...</td>\n",
       "      <td>O NORP O PERSON O PERSON O NORP O O O LANGUAGE...</td>\n",
       "      <td>UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O B I I I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from which countries did the norse originate ?</td>\n",
       "      <td>the normans ( norman : nourmands ; french : no...</td>\n",
       "      <td>DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...</td>\n",
       "      <td>O NORP O PERSON O PERSON O NORP O O O LANGUAGE...</td>\n",
       "      <td>UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who was the norse leader ?</td>\n",
       "      <td>the normans ( norman : nourmands ; french : no...</td>\n",
       "      <td>DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...</td>\n",
       "      <td>O NORP O PERSON O PERSON O NORP O O O LANGUAGE...</td>\n",
       "      <td>UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what century did the normans first gain their ...</td>\n",
       "      <td>the normans ( norman : nourmands ; french : no...</td>\n",
       "      <td>DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...</td>\n",
       "      <td>O NORP O PERSON O PERSON O NORP O O O LANGUAGE...</td>\n",
       "      <td>UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0              in what country is normandy located ?   \n",
       "1                when were the normans in normandy ?   \n",
       "2     from which countries did the norse originate ?   \n",
       "3                         who was the norse leader ?   \n",
       "4  what century did the normans first gain their ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  the normans ( norman : nourmands ; french : no...   \n",
       "1  the normans ( norman : nourmands ; french : no...   \n",
       "2  the normans ( norman : nourmands ; french : no...   \n",
       "3  the normans ( norman : nourmands ; french : no...   \n",
       "4  the normans ( norman : nourmands ; french : no...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...   \n",
       "1  DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...   \n",
       "2  DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...   \n",
       "3  DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...   \n",
       "4  DET PROPN PUNCT PROPN PUNCT NOUN PUNCT PROPN P...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  O NORP O PERSON O PERSON O NORP O O O LANGUAGE...   \n",
       "1  O NORP O PERSON O PERSON O NORP O O O LANGUAGE...   \n",
       "2  O NORP O PERSON O PERSON O NORP O O O LANGUAGE...   \n",
       "3  O NORP O PERSON O PERSON O NORP O O O LANGUAGE...   \n",
       "4  O NORP O PERSON O PERSON O NORP O O O LANGUAGE...   \n",
       "\n",
       "                                                case  \\\n",
       "0  UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...   \n",
       "1  UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...   \n",
       "2  UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...   \n",
       "3  UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...   \n",
       "4  UP UP LOW UP LOW UP LOW UP LOW UP LOW UP LOW U...   \n",
       "\n",
       "                                                 BIO  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O B I I I ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "4  O O O O O O O O O O O O O O O O O O O O O O O ...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev = squad_dev.drop(['answer', 'answer_start', 'title', 'is_impossible'], axis=1)\n",
    "squad_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev.to_csv('dataset/squad_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squad_train['POS'] = ''\n",
    "squad_train['NER'] = ''\n",
    "squad_train['case'] = ''\n",
    "squad_train['BIO'] = ''\n",
    "for idx, text, answer, answer_start in squad_train[['context', 'answer', 'answer_start']].itertuples():\n",
    "    squad_train['POS'][idx], squad_train['NER'][idx], squad_train['case'][idx], squad_train['BIO'][idx], squad_train['context'][idx] = features_en(text, answer, answer_start, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train['question'] = squad_train['question'].apply(lambda x: tokenize_en(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "      <th>case</th>\n",
       "      <th>BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...</td>\n",
       "      <td>when did beyonce start becoming popular ?</td>\n",
       "      <td>PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...</td>\n",
       "      <td>O O O O O O O O O O O O O O O DATE DATE DATE D...</td>\n",
       "      <td>UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...</td>\n",
       "      <td>O O O O O O O O O O O O O O O DATE DATE DATE D...</td>\n",
       "      <td>UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...</td>\n",
       "      <td>when did beyonce leave destiny 's child and be...</td>\n",
       "      <td>PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...</td>\n",
       "      <td>O O O O O O O O O O O O O O O DATE DATE DATE D...</td>\n",
       "      <td>UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...</td>\n",
       "      <td>in what city and state did beyonce   grow up ?</td>\n",
       "      <td>PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...</td>\n",
       "      <td>O O O O O O O O O O O O O O O DATE DATE DATE D...</td>\n",
       "      <td>UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...</td>\n",
       "      <td>in which decade did beyonce become famous ?</td>\n",
       "      <td>PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...</td>\n",
       "      <td>O O O O O O O O O O O O O O O DATE DATE DATE D...</td>\n",
       "      <td>UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...   \n",
       "1  beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...   \n",
       "2  beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...   \n",
       "3  beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...   \n",
       "4  beyoncé giselle knowles - carter ( /biːˈjɒnseɪ...   \n",
       "\n",
       "                                            question  \\\n",
       "0          when did beyonce start becoming popular ?   \n",
       "1  what areas did beyonce compete in when she was...   \n",
       "2  when did beyonce leave destiny 's child and be...   \n",
       "3     in what city and state did beyonce   grow up ?   \n",
       "4        in which decade did beyonce become famous ?   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...   \n",
       "1  PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...   \n",
       "2  PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...   \n",
       "3  PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...   \n",
       "4  PROPN PROPN PROPN PUNCT PROPN PUNCT ADJ NOUN P...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  O O O O O O O O O O O O O O O DATE DATE DATE D...   \n",
       "1  O O O O O O O O O O O O O O O DATE DATE DATE D...   \n",
       "2  O O O O O O O O O O O O O O O DATE DATE DATE D...   \n",
       "3  O O O O O O O O O O O O O O O DATE DATE DATE D...   \n",
       "4  O O O O O O O O O O O O O O O DATE DATE DATE D...   \n",
       "\n",
       "                                                case  \\\n",
       "0  UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...   \n",
       "1  UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...   \n",
       "2  UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...   \n",
       "3  UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...   \n",
       "4  UP UP UP LOW UP LOW LOW LOW LOW UP LOW LOW LOW...   \n",
       "\n",
       "                                                 BIO  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "4  O O O O O O O O O O O O O O O O O O O O O O O ...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train = squad_train.drop(['answer', 'answer_start', 'title', 'is_impossible'], axis=1)\n",
    "squad_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train.to_csv('dataset/squad_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-20 14:04:28.971 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1220 14:04:28.971092 140166193248064 download.py:117] Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "2019-12-20 14:04:33.698 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz download because of matching hashes\n",
      "I1220 14:04:33.698825 140166193248064 download.py:117] Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz download because of matching hashes\n",
      "[nltk_data] Downloading package punkt to /home/julia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/julia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/julia/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/julia/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "W1220 14:04:34.008934 140166193248064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "2019-12-20 14:04:34.580 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/julia/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n",
      "I1220 14:04:34.580994 140166193248064 simple_vocab.py:112] [loading vocabulary from /home/julia/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n",
      "W1220 14:04:34.604461 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1220 14:04:34.607667 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:223: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1220 14:04:34.609919 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:223: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1220 14:04:34.672343 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W1220 14:04:34.696746 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_ner.py:126: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1220 14:04:34.754666 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_ner.py:227: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1220 14:04:34.804173 140166193248064 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1220 14:04:35.877326 140166193248064 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1220 14:04:35.963636 140166193248064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1220 14:04:36.086305 140166193248064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W1220 14:04:40.704122 140166193248064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1220 14:04:40.801457 140166193248064 deprecation.py:323] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_ner.py:350: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1220 14:04:41.192008 140166193248064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W1220 14:04:41.565810 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:235: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W1220 14:04:59.645488 140166193248064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1220 14:05:21.816219 140166193248064 deprecation.py:323] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/models/bert/bert_ner.py:139: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2019-12-20 14:05:21.838 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/julia/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n",
      "I1220 14:05:21.838616 140166193248064 tf_model.py:52] [loading model from /home/julia/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n",
      "W1220 14:05:21.849607 140166193248064 deprecation_wrapper.py:119] From /home/julia/.local/lib/python3.6/site-packages/deeppavlov/core/models/tf_model.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = RNNMorphPredictor(language=\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_ru(text, predictor, ner_model, answer, answer_start):\n",
    "    \n",
    "    right = text[0:answer_start]\n",
    "    answer = text[answer_start:answer_start+len(answer)]\n",
    "    left = text[answer_start+len(answer):len(text)+1]    \n",
    "    \n",
    "    pos = []\n",
    "    ner = []\n",
    "    case = []\n",
    "    bio = []\n",
    "    tokenized = []\n",
    "\n",
    "    right_tokenized = WordPunctTokenizer().tokenize(right)\n",
    "    answer_tokenized = WordPunctTokenizer().tokenize(answer)\n",
    "    left_tokenized = WordPunctTokenizer().tokenize(left)\n",
    "    \n",
    "    for token in right_tokenized:\n",
    "        if token != '' and not token.isspace():\n",
    "            tokenized.append(token.lower())\n",
    "\n",
    "            if token[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            bio.append('O')\n",
    "    \n",
    "    for token in answer_tokenized:\n",
    "        if token != '' and not token.isspace():\n",
    "            tokenized.append(token.lower())\n",
    "\n",
    "            if token[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            if answer_tokenized.index(token) == 0:\n",
    "                bio.append('B')\n",
    "            else:\n",
    "                bio.append('I')\n",
    "    \n",
    "    for token in left_tokenized:\n",
    "        if token != '' and not token.isspace():\n",
    "            tokenized.append(token.lower())\n",
    "\n",
    "            if token[0].isupper():\n",
    "                case.append('UP')\n",
    "            else:\n",
    "                case.append('LOW')\n",
    "            bio.append('O')\n",
    "    \n",
    "    forms = predictor.predict(tokenized)\n",
    "    pos = [form.pos for form in forms]\n",
    "    ner = ner_model([tokenized])\n",
    "        \n",
    "    return (' '.join(pos)), (' '.join(ner[1][0])), (' '.join(case)), (' '.join(bio)), (' '.join(tokenized))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_dev['POS'] = ''\n",
    "sberquad_dev['NER'] = ''\n",
    "sberquad_dev['case'] = ''\n",
    "sberquad_dev['BIO'] = ''\n",
    "for idx, text, answer, answer_start in sberquad_dev[['context', 'answer', 'answer_start']].itertuples():\n",
    "    try:\n",
    "        sberquad_dev['POS'][idx], sberquad_dev['NER'][idx], sberquad_dev['case'][idx], sberquad_dev['BIO'][idx], sberquad_dev['context'][idx] = features_ru(text, predictor, ner_model, answer, answer_start)\n",
    "    except RuntimeError:\n",
    "        sberquad_dev = sberquad_dev.drop([idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_dev['question'] = sberquad_dev['question'].apply(lambda x: ' '.join(WordPunctTokenizer().tokenize(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "      <th>case</th>\n",
       "      <th>BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>в миссолонги байрон заболел лихорадкой , продо...</td>\n",
       "      <td>чем заболел байрон в миссолонги ?</td>\n",
       "      <td>ADP NOUN NOUN VERB NOUN PUNCT VERB VERB DET DE...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O B-DATE I-DAT...</td>\n",
       "      <td>UP UP UP LOW LOW LOW LOW LOW LOW LOW LOW LOW L...</td>\n",
       "      <td>O O O O B O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>от излишней потери тепла млекопитающих предохр...</td>\n",
       "      <td>как отводятся излишки тепла у млекопитающих ?</td>\n",
       "      <td>ADP ADJ NOUN NOUN NOUN VERB ADJ NOUN PUNCT CON...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O B O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>хромосомные перестройки ( хромосомные аберраци...</td>\n",
       "      <td>что нарушают хромосомные аберрации ?</td>\n",
       "      <td>ADJ NOUN PUNCT ADJ NOUN PUNCT PUNCT PART NOUN ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O B I O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>первый в мире городской автобус с двигателем в...</td>\n",
       "      <td>в каком городе первый в мире городской автобус...</td>\n",
       "      <td>ADJ ADP NOUN ADJ NOUN ADP NOUN ADJ NOUN VERB A...</td>\n",
       "      <td>B-ORDINAL O O O O O O O O O O O B-DATE I-DATE ...</td>\n",
       "      <td>UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O B I O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>фродом являются также и операции с поддельными...</td>\n",
       "      <td>в каком режиме проходят подлимитные операции ?</td>\n",
       "      <td>NOUN VERB ADV PART NOUN ADP ADJ NOUN PUNCT VER...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW LOW LOW LOW LOW LOW UP LOW LOW ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  в миссолонги байрон заболел лихорадкой , продо...   \n",
       "1  от излишней потери тепла млекопитающих предохр...   \n",
       "2  хромосомные перестройки ( хромосомные аберраци...   \n",
       "3  первый в мире городской автобус с двигателем в...   \n",
       "4  фродом являются также и операции с поддельными...   \n",
       "\n",
       "                                            question  \\\n",
       "0                  чем заболел байрон в миссолонги ?   \n",
       "1      как отводятся излишки тепла у млекопитающих ?   \n",
       "2               что нарушают хромосомные аберрации ?   \n",
       "3  в каком городе первый в мире городской автобус...   \n",
       "4     в каком режиме проходят подлимитные операции ?   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  ADP NOUN NOUN VERB NOUN PUNCT VERB VERB DET DE...   \n",
       "1  ADP ADJ NOUN NOUN NOUN VERB ADJ NOUN PUNCT CON...   \n",
       "2  ADJ NOUN PUNCT ADJ NOUN PUNCT PUNCT PART NOUN ...   \n",
       "3  ADJ ADP NOUN ADJ NOUN ADP NOUN ADJ NOUN VERB A...   \n",
       "4  NOUN VERB ADV PART NOUN ADP ADJ NOUN PUNCT VER...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  O O O O O O O O O O O O O O O O O B-DATE I-DAT...   \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "3  B-ORDINAL O O O O O O O O O O O B-DATE I-DATE ...   \n",
       "4  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "\n",
       "                                                case  \\\n",
       "0  UP UP UP LOW LOW LOW LOW LOW LOW LOW LOW LOW L...   \n",
       "1  UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...   \n",
       "2  UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...   \n",
       "3  UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...   \n",
       "4  UP LOW LOW LOW LOW LOW LOW LOW LOW UP LOW LOW ...   \n",
       "\n",
       "                                                 BIO  \n",
       "0  O O O O B O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O O O B O ...  \n",
       "2  O O O O O O O O O O O B I O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O B I O O O O O ...  \n",
       "4  O O O O O O O O O O O O O O O O O O O O O O O ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sberquad_dev = sberquad_dev.drop(['answer', 'answer_start'], axis=1)\n",
    "sberquad_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_dev.to_csv('dataset/sberquad_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_train['POS'] = ''\n",
    "sberquad_train['NER'] = ''\n",
    "sberquad_train['case'] = ''\n",
    "sberquad_train['BIO'] = ''\n",
    "for idx, text, answer, answer_start in sberquad_train[['context', 'answer', 'answer_start']].itertuples():\n",
    "    try:\n",
    "        sberquad_train['POS'][idx], sberquad_train['NER'][idx], sberquad_train['case'][idx], sberquad_train['BIO'][idx], sberquad_train['context'][idx] = features_ru(text, predictor, ner_model, answer, answer_start)\n",
    "    except RuntimeError:\n",
    "        sberquad_train = sberquad_train.drop([idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_train['question'] = sberquad_train['question'].apply(lambda x: ' '.join(WordPunctTokenizer().tokenize(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "      <th>case</th>\n",
       "      <th>BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>в допетровское время искусство в россии имело ...</td>\n",
       "      <td>чем на руси ограничивались проявления пластики ?</td>\n",
       "      <td>ADP ADJ NOUN NOUN ADP NOUN VERB DET NOUN VERB ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW LOW UP LOW LOW LOW LOW LOW LOW ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>по данным рейтинга top 100 самых филиальных ба...</td>\n",
       "      <td>какое место занимает убрир по даным рейтинга t...</td>\n",
       "      <td>ADP NOUN NOUN PUNCT NUM ADJ ADJ NOUN NOUN NOUN...</td>\n",
       "      <td>O O O O B-CARDINAL O O O B-GPE O B-ORG O O O O...</td>\n",
       "      <td>UP LOW LOW UP LOW LOW LOW LOW UP LOW UP LOW UP...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O B I O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>смарт - стекло — современный собирательный тер...</td>\n",
       "      <td>какие свойства в общем способно изменять смарт...</td>\n",
       "      <td>NOUN PUNCT NOUN PUNCT ADJ ADJ NOUN ADP NOUN PU...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>во время интервенции в россию речи посполитой ...</td>\n",
       "      <td>как звали воеводу дорогобужа , который сдал го...</td>\n",
       "      <td>ADP NOUN NOUN ADP NOUN NOUN ADJ NOUN NUM PUNCT...</td>\n",
       "      <td>O O O O O O O B-DATE I-DATE I-DATE I-DATE I-DA...</td>\n",
       "      <td>UP LOW LOW LOW UP UP UP LOW LOW LOW LOW LOW LO...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>в начале 1823 года грибоедов на время покинул ...</td>\n",
       "      <td>в каком году грибоедов написал водевиль кто бр...</td>\n",
       "      <td>ADP NOUN NUM NOUN NOUN ADP NOUN VERB NOUN CONJ...</td>\n",
       "      <td>O B-DATE I-DATE I-DATE B-PERSON O O O O O O O ...</td>\n",
       "      <td>UP LOW LOW LOW UP LOW LOW LOW LOW LOW LOW LOW ...</td>\n",
       "      <td>O O B O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  в допетровское время искусство в россии имело ...   \n",
       "1  по данным рейтинга top 100 самых филиальных ба...   \n",
       "2  смарт - стекло — современный собирательный тер...   \n",
       "3  во время интервенции в россию речи посполитой ...   \n",
       "4  в начале 1823 года грибоедов на время покинул ...   \n",
       "\n",
       "                                            question  \\\n",
       "0   чем на руси ограничивались проявления пластики ?   \n",
       "1  какое место занимает убрир по даным рейтинга t...   \n",
       "2  какие свойства в общем способно изменять смарт...   \n",
       "3  как звали воеводу дорогобужа , который сдал го...   \n",
       "4  в каком году грибоедов написал водевиль кто бр...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  ADP ADJ NOUN NOUN ADP NOUN VERB DET NOUN VERB ...   \n",
       "1  ADP NOUN NOUN PUNCT NUM ADJ ADJ NOUN NOUN NOUN...   \n",
       "2  NOUN PUNCT NOUN PUNCT ADJ ADJ NOUN ADP NOUN PU...   \n",
       "3  ADP NOUN NOUN ADP NOUN NOUN ADJ NOUN NUM PUNCT...   \n",
       "4  ADP NOUN NUM NOUN NOUN ADP NOUN VERB NOUN CONJ...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "1  O O O O B-CARDINAL O O O B-GPE O B-ORG O O O O...   \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "3  O O O O O O O B-DATE I-DATE I-DATE I-DATE I-DA...   \n",
       "4  O B-DATE I-DATE I-DATE B-PERSON O O O O O O O ...   \n",
       "\n",
       "                                                case  \\\n",
       "0  UP LOW LOW LOW LOW UP LOW LOW LOW LOW LOW LOW ...   \n",
       "1  UP LOW LOW UP LOW LOW LOW LOW UP LOW UP LOW UP...   \n",
       "2  UP LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW LOW...   \n",
       "3  UP LOW LOW LOW UP UP UP LOW LOW LOW LOW LOW LO...   \n",
       "4  UP LOW LOW LOW UP LOW LOW LOW LOW LOW LOW LOW ...   \n",
       "\n",
       "                                                 BIO  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O O B I O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "4  O O B O O O O O O O O O O O O O O O O O O O O ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sberquad_train = sberquad_train.drop(['answer', 'answer_start'], axis=1)\n",
    "sberquad_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sberquad_train.to_csv('dataset/sberquad_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45018"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sberquad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
